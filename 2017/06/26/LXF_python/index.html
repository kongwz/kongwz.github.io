<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Python," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="#爬取Python教程博客并转成PDF今天我们爬取一下python教程博客并把爬取内容转换成PDF储存到本地。用到的工具  requestsBeautifulSouptimepdfkitwkhtmltopdf">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="爬取Python教程博客并转成PDF">
<meta property="og:url" content="http://kongwz.cn/2017/06/26/LXF_python/index.html">
<meta property="og:site_name" content="Kelo&#39;s blog">
<meta property="og:description" content="#爬取Python教程博客并转成PDF今天我们爬取一下python教程博客并把爬取内容转换成PDF储存到本地。用到的工具  requestsBeautifulSouptimepdfkitwkhtmltopdf">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf01.png">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf02.png">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf03.png">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf04.png">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/LXF05.png">
<meta property="og:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf06.png">
<meta property="og:updated_time" content="2019-05-29T09:27:11.938Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="爬取Python教程博客并转成PDF">
<meta name="twitter:description" content="#爬取Python教程博客并转成PDF今天我们爬取一下python教程博客并把爬取内容转换成PDF储存到本地。用到的工具  requestsBeautifulSouptimepdfkitwkhtmltopdf">
<meta name="twitter:image" content="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf01.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://kongwz.cn/2017/06/26/LXF_python/"/>





  <title>爬取Python教程博客并转成PDF | Kelo's blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Kelo's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://kongwz.cn/2017/06/26/LXF_python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Kelo">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kelo's blog">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">爬取Python教程博客并转成PDF</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-26T21:30:52+08:00">
                2017-06-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2017/06/26/LXF_python/" class="leancloud_visitors" data-flag-title="爬取Python教程博客并转成PDF">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>#爬取Python教程博客并转成PDF<br>今天我们爬取一下python教程博客并把爬取内容转换成PDF储存到本地。<br><strong>用到的工具</strong></p>
<blockquote>
<p>requests<br>BeautifulSoup<br>time<br>pdfkit<br>wkhtmltopdf </p>
</blockquote>
<a id="more"></a>
<p>我们先说一下本次要用到的两个库</p>
<ul>
<li>pdfkit 这个是将转换PDF的一个工具库。我们可以指定命令安装一下（前提要安装pip）<em>pip install pdfkit</em>  pdfkit 是 wkhtmltopdf 的Python封装包。首先安装好下面的依赖包，接着安装 wkhtmltopdf</li>
<li>time  这个我们可以用来获取程序执行的时间 time.time()<br>##安装wkhtmltopdf<br>windows平台直接去wkhtmltopdf官网下载稳定版本并安装就行了，安装好后要记得配置PATH 环境变量。安装好后我们可以在cmd命令窗口测试一下是否配置成功。 wkhtmltopdf <a href="http://www.baidu.com/" target="_blank" rel="noopener">http://www.baidu.com/</a> D:test.pdf （这里要注意一下网址和pdf名字之间是有个空格的）<br>##好了，工具准备就绪，我们先分析一下网页<br>我们先打开廖老师python教程的网址<a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="noopener">http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000</a><br>可以看到博客左侧是教程目录，右侧是教程正文。我们的思路是把每个目录对应的正文html保存到本地，然后使用pdfkit转换成pdf<br><strong>我们先看一下教程正文</strong><br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf01.png" alt="图1"><br>看到下图，我们只需要拿到教程中正文部分就够了，至于那些评论、广告、、是我们不需要的，所以我们先要找到正文对应的标签名字。<br>我们使用Chrome浏览器自带的工具，选取教程正文，然后我们找到正文对应的标签，这里我们看到标签是x-wiki-content 然后我们就可以开始撸代码了。<br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf02.png" alt="图2"><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(url)</span><br><span class="line">soup = BeautifulSoup(response.content, <span class="string">'html.parser'</span>)</span><br><span class="line"><span class="comment"># 正文</span></span><br><span class="line">body = soup.find_all(class_=<span class="string">"x-wiki-content"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>注意我们还没有获取正文的标题文字<br>跟上面相同的方法我们找到正文上面标题文字的对应标签<br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf03.png" alt="图3"><br>这里我们看到正文对应的标题文字标签是x-content 下的h4标签我们可以使用x-content获取标题，当然也可以使用h4获取，这里我是用的h4<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标题</span></span><br><span class="line">title = soup.find_all(<span class="string">'h4'</span>)[0].get_text()</span><br></pre></td></tr></table></figure></p>
<p>然后我们将获取到的正文信息保存到html中，注意原文中的图片使用的相对路径，这样的话我们是访问不到图片的，我们需要改成绝对路径。（有关相对路径和绝对路径不是很清楚的话可以在这里了解一下）<a href="http://jingyan.baidu.com/article/a3a3f811f795518da2eb8af9.html" target="_blank" rel="noopener">相对路径和绝对路径的区别</a>.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">html = h[1:-1]</span><br><span class="line"><span class="comment">#print(html)</span></span><br><span class="line"><span class="comment">#body中的img标签的src相对路径的改成绝对路径</span></span><br><span class="line">pattern = <span class="string">"(&lt;img .*?src=\")(.*?)(\")"</span></span><br><span class="line">def func(m):</span><br><span class="line">    <span class="keyword">if</span> not m.group(3).startswith(<span class="string">"http"</span>):</span><br><span class="line">        rtn = m.group(1) + domain + m.group(2) + m.group(3)</span><br><span class="line">        <span class="built_in">return</span> rtn</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">return</span> m.group(1) + m.group(2) + m.group(3)       </span><br><span class="line">html = re.compile(pattern).sub(func, html)</span><br><span class="line">html = html_template.format(content=html)</span><br><span class="line">html = html.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">with open(name, <span class="string">'wb'</span>) as f:</span><br><span class="line">    f.write(html)</span><br></pre></td></tr></table></figure></p>
<p>##下面我们找出所有目录链接<br>跟获取正文信息一样，我们要找到目录列表所对应的标签。<br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf04.png" alt="图4"><br>这里目录对应的标签是x-sidebar-left-content 我们获取到目录对应链接是href=”/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000”<br>这里我们是并不能直接访问的 ，我 们需要处理一下，’href=’肯定是不能要的，所以我们要把这个去掉，然后发现后面这个链接是不全的（对应我们教程的链接）缺少了<a href="http://www.liaoxuefeng.com" target="_blank" rel="noopener">http://www.liaoxuefeng.com</a><br>所以我们要拼接一下路径字符串，处理成正常可以访问的路径<br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/LXF05.png" alt="图5"><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def get_url_list(url):</span><br><span class="line">    last_position = find_last(url, <span class="string">"/"</span>) + 1</span><br><span class="line">    <span class="comment">#print(last_position)</span></span><br><span class="line">    tutorial_url_head = url[0:last_position]</span><br><span class="line">    global domain</span><br><span class="line">    domain = get_domain(url)</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(response.content, <span class="string">"html.parser"</span>)</span><br><span class="line">    menu_tag = soup.find(class_=<span class="string">"x-sidebar-left-content"</span>)</span><br><span class="line">    urls = []</span><br><span class="line">    <span class="comment">#拼接链接地址字符串</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> menu_tag.find_all(<span class="string">'a'</span>):</span><br><span class="line">        href = str(a.get(<span class="string">'href'</span>))</span><br><span class="line">        result = href.find(<span class="string">'/'</span>)</span><br><span class="line">        <span class="keyword">if</span> result == -1:</span><br><span class="line">            url = tutorial_url_head + href</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            url = domain + href</span><br><span class="line">        urls.append(url)</span><br><span class="line">    <span class="built_in">return</span> urls</span><br></pre></td></tr></table></figure></p>
<p>##最后一步，保存html为PDF<br>pdfkit提供了很多种选择格式，我们可以根据自己的需要去设置参数。这里就不一一介绍了，有兴趣的好可以去了解一下<a href="http://www.jianshu.com/p/4d65857ffe5e" target="_blank" rel="noopener">HTML 转 PDF 之 wkhtmltopdf 工具精讲</a>.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def save_pdf(htmls, file_name):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    把所有html文件保存到pdf文件</span></span><br><span class="line"><span class="string">    :param htmls:  html文件列表</span></span><br><span class="line"><span class="string">    :param file_name: pdf文件名</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    options = &#123;        </span><br><span class="line">        <span class="string">'page-size'</span>: <span class="string">'Letter'</span>,</span><br><span class="line">        <span class="string">'encoding'</span>: <span class="string">"UTF-8"</span>,</span><br><span class="line">        <span class="string">'custom-header'</span>: [</span><br><span class="line">            (<span class="string">'Accept-Encoding'</span>, <span class="string">'gzip'</span>)</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    pdfkit.from_file(htmls, file_name, options=options)</span><br></pre></td></tr></table></figure></p>
<p>##爬取结果<br>这篇案例到这里差不多就结束了，我们看一下爬取结果。<br><img src="https://blogimages-1253307164.cos.ap-shanghai.myqcloud.com/lxf06.png" alt="图6"></p>
<p>##全部代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding=utf-8 -*-</span></span><br><span class="line">import os</span><br><span class="line">import re</span><br><span class="line">import time</span><br><span class="line">from urllib.parse import urlparse</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import pdfkit</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">html_template = <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="string">&lt;html lang="</span>en<span class="string">"&gt;</span></span><br><span class="line"><span class="string">&lt;head&gt;</span></span><br><span class="line"><span class="string">    &lt;meta charset="</span>UTF-8<span class="string">"&gt;</span></span><br><span class="line"><span class="string">&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&#123;content&#125;</span></span><br><span class="line"><span class="string">&lt;/body&gt;</span></span><br><span class="line"><span class="string">&lt;/html&gt;</span></span><br><span class="line"><span class="string">"</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_url_list(url):</span><br><span class="line">    last_position = find_last(url, <span class="string">"/"</span>) + 1</span><br><span class="line">    <span class="comment">#print(last_position)</span></span><br><span class="line">    tutorial_url_head = url[0:last_position]</span><br><span class="line">    global domain</span><br><span class="line">    domain = get_domain(url)</span><br><span class="line">    response = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(response.content, <span class="string">"html.parser"</span>)</span><br><span class="line">    menu_tag = soup.find(class_=<span class="string">"x-sidebar-left-content"</span>)</span><br><span class="line">    urls = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> menu_tag.find_all(<span class="string">'a'</span>):</span><br><span class="line">        href = str(a.get(<span class="string">'href'</span>))</span><br><span class="line">        result = href.find(<span class="string">'/'</span>)</span><br><span class="line">        <span class="keyword">if</span> result == -1:</span><br><span class="line">            url = tutorial_url_head + href</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            url = domain + href</span><br><span class="line">        urls.append(url)</span><br><span class="line">    <span class="built_in">return</span> urls</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse_url_to_html(url, name):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    解析URL，返回HTML内容</span></span><br><span class="line"><span class="string">    :param url:解析的url</span></span><br><span class="line"><span class="string">    :param name: 保存的html文件名</span></span><br><span class="line"><span class="string">    :return: html</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    try:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        soup = BeautifulSoup(response.content, <span class="string">'html.parser'</span>)</span><br><span class="line">        <span class="comment"># 正文</span></span><br><span class="line">        body = soup.find_all(class_=<span class="string">"x-wiki-content"</span>)</span><br><span class="line">        <span class="comment">#print(body)</span></span><br><span class="line">        <span class="comment"># 标题</span></span><br><span class="line">        title = soup.find_all(<span class="string">'h4'</span>)[0].get_text()</span><br><span class="line">        <span class="comment">#print(title)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 标题加入到正文的最前面，居中显示</span></span><br><span class="line">        center_tag = soup.new_tag(<span class="string">"center"</span>)</span><br><span class="line">        title_tag = soup.new_tag(<span class="string">'h1'</span>)</span><br><span class="line">        title_tag.string = title</span><br><span class="line">        center_tag.insert(0, title_tag)</span><br><span class="line">        body.insert(0, center_tag)</span><br><span class="line">        h = str(body)</span><br><span class="line">        html = h[1:-1]</span><br><span class="line">        <span class="comment">#print(html)</span></span><br><span class="line">        <span class="comment">#body中的img标签的src相对路径的改成绝对路径</span></span><br><span class="line">        pattern = <span class="string">"(&lt;img .*?src=\")(.*?)(\")"</span></span><br><span class="line">        </span><br><span class="line">        def func(m):</span><br><span class="line">            <span class="keyword">if</span> not m.group(3).startswith(<span class="string">"http"</span>):</span><br><span class="line">                rtn = m.group(1) + domain + m.group(2) + m.group(3)</span><br><span class="line">                <span class="built_in">return</span> rtn</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">return</span> m.group(1) + m.group(2) + m.group(3)</span><br><span class="line">       </span><br><span class="line">        html = re.compile(pattern).sub(func, html)</span><br><span class="line">        html = html_template.format(content=html)</span><br><span class="line">        html = html.encode(<span class="string">"utf-8"</span>)</span><br><span class="line">        with open(name, <span class="string">'wb'</span>) as f:</span><br><span class="line">            f.write(html)</span><br><span class="line">        <span class="built_in">return</span> name</span><br><span class="line"></span><br><span class="line">    except Exception as e:</span><br><span class="line">        <span class="comment"># logging.error("解析错误: " + e, exc_info=True)</span></span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def save_pdf(htmls, file_name):</span><br><span class="line">    <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">    把所有html文件保存到pdf文件</span></span><br><span class="line"><span class="string">    :param htmls:  html文件列表</span></span><br><span class="line"><span class="string">    :param file_name: pdf文件名</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line">    options = &#123;        </span><br><span class="line">        <span class="string">'page-size'</span>: <span class="string">'Letter'</span>,</span><br><span class="line">        <span class="string">'encoding'</span>: <span class="string">"UTF-8"</span>,</span><br><span class="line">        <span class="string">'custom-header'</span>: [</span><br><span class="line">            (<span class="string">'Accept-Encoding'</span>, <span class="string">'gzip'</span>)</span><br><span class="line">        ]</span><br><span class="line">    &#125;</span><br><span class="line">    pdfkit.from_file(htmls, file_name, options=options)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def find_last(string, char):</span><br><span class="line">    last_position = -1</span><br><span class="line">    <span class="keyword">while</span> True:</span><br><span class="line">        position = string.find(char, last_position + 1)</span><br><span class="line">        <span class="keyword">if</span> position == -1:</span><br><span class="line">            <span class="built_in">return</span> last_position</span><br><span class="line">        last_position = position</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_domain(url):</span><br><span class="line">    r = urlparse(url)</span><br><span class="line">    <span class="built_in">return</span> r.scheme + <span class="string">"://"</span> + r.netloc</span><br><span class="line"></span><br><span class="line"><span class="comment">#我们要运行的主函数</span></span><br><span class="line">def main():</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"数据读取中,请稍后..."</span>)</span><br><span class="line">	url = <span class="string">"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000"</span></span><br><span class="line">	start = time.time()</span><br><span class="line">	<span class="comment">#获取url列表</span></span><br><span class="line">	urls = get_url_list(url)</span><br><span class="line">	<span class="comment">#要保存的pdf名字</span></span><br><span class="line">	file_name = <span class="string">"LXF_python.pdf"</span></span><br><span class="line">	<span class="comment">#保存html并拿到列表</span></span><br><span class="line">	htmls = [parse_url_to_html(url, str(index) + <span class="string">".html"</span>) <span class="keyword">for</span> index , url <span class="keyword">in</span> enumerate(urls)]</span><br><span class="line">	<span class="comment">#print(htmls)</span></span><br><span class="line">	<span class="comment">#保存到pdf</span></span><br><span class="line">	save_pdf(htmls , file_name)</span><br><span class="line">	<span class="comment">#删除我们保存到本地的html文件</span></span><br><span class="line">	<span class="keyword">for</span> html <span class="keyword">in</span> htmls:</span><br><span class="line">		os.remove(html)</span><br><span class="line">	total_time = time.time() - start</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">"数据读取完毕,总共用时： %f 秒"</span> % total_time)</span><br><span class="line"><span class="comment">#设定主函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<p>好了，就到这里吧，祝大家生活愉快。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/weixin.png" alt="Kelo WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/zhifubao.png" alt="Kelo Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/06/05/python-2/" rel="next" title="python爬虫模拟浏览器的两种方法">
                <i class="fa fa-chevron-left"></i> python爬虫模拟浏览器的两种方法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/05/huizong/" rel="prev" title="学习资料">
                学习资料 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNzk4NC8xNDUxNA"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/head.png"
               alt="Kelo" />
          <p class="site-author-name" itemprop="name">Kelo</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/kongwz" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友链
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://no-nothing.github.io/" title="no-nothing" target="_blank">no-nothing</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

      

    </div>

    

  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kelo</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user">本站访客数</i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye">本站总访问量</i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("WfsTKkATCOFW291wPQOIeQHS-gzGzoHsz", "mn2y41AjTzIoIyTOx5p6bFt3");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

  




</body>
</html>
<!-- 页面点击小红心 --> <script type="text/javascript" src="/js/src/love.js"></script>